---
title: " Lab session practice"
author: "Slawski and Ben-David"
date: "8/21/2019"
output: beamer_presentation
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Ground Truth: all variables with correct correspondence 

- Import the original data and check perform a LS regression
- This regression is the oracle model

```{r, echo=TRUE}
wages_f <- read.csv("../data/fakedata/wages_df.csv",
                    header = TRUE)
lm0 <- lm(log(WAGE) ~ SEX
          + EXPERIENCE + I(EXPERIENCE^2)
          + EDUCATION + as.factor(OCCUPATION)
          + UNION, data = wages_f)

```

## R summary

```{r, echo=TRUE}
coef(lm0)

```

## Importing wages data files

- First import the data files.

```{r , echo = TRUE}

wages_dA <- read.csv("../data/fakedata/wages_dA.csv", header = TRUE)
wages_dB <- read.csv("../data/fakedata/wages_dB.csv", header = TRUE)

```


- Check both data files
- What variables are approriate for linkage?


```{r , echo= FALSE}
colnames(wages_dA)
colnames(wages_dB)
```
## Linking the  data files

- Upload the R package **fastLink** for linkg files



```{r , echo= FALSE}
library(fastLink)

```

- In this experiment we link two files based on **ZIPCODE**.

- Check *fastlink* function first.

```{r cars, echo = TRUE}
help(fastLink)
```

- To specify matching variables we choose varnames = "ZIPCODE".

```{r, echo=TRUE}
set.seed(1427)
wages_link<-fastLink(wages_dA, wages_dB, varnames = "ZIPCODE")
```



## The linked data

- We can get the linked data file form *getMatch" function.

```{r, echo=TRUE}
matched_wages <- getMatches(wages_dA, 
                  wages_dB, wages_link, combine.dfs = FALSE)

dA<-matched_wages$dfA.match; dB<-matched_wages$dfB.match
```
## Merging  these two files


- First ensure unique column names in the merged file

```{r, echo = TRUE}
commonvars <- intersect(colnames(dA), colnames(dB))
colnames(dA)[colnames(dA) %in% commonvars] <- 
  paste("A.", colnames(dA)[colnames(dA) %in%
        commonvars], sep="")
colnames(dB)[colnames(dB) %in% commonvars] <-
        paste("B.", colnames(dB)[colnames(dB)
               %in% commonvars], sep="")

```



## Merge the data linked by fastLink

```{r, echo= TRUE}

merged_wages <-cbind.data.frame(dA, dB)

```
- Compute the fraction of mismatches (about $13\%$)


```{r, echo= TRUE}
mean(merged_wages[,"A.ID"] != merged_wages[,"B.ID"])
```

```{echo= TRUE, fig.height= 5, fig.width= 4}
plot(wages_f$WAGE[merged_wages[,"A.ID"]],
     wages_f$WAGE[merged_wages[,"B.ID"]])
```
## Check the linear regression with linked file

```{r, echo= TRUE}
lm_merged <- lm(log(WAGE) ~ B.SEX 
              + EXPERIENCE + I(EXPERIENCE^2) 
              +  EDUCATION + as.factor(OCCUPATION)
              + UNION, data = merged_wages)
```

## Ceofficients of Naive LS regression

```{r,echo= TRUE}
coef(lm_merged)
```
- compare the result with the original regression with original data

## Robust regression

- Try robust regression with Huber loss

```{r, echo= TRUE}
library(MASS)
rlm_merged <- rlm(log(WAGE) ~ B.SEX + EXPERIENCE + I(EXPERIENCE^2)  + 
            EDUCATION + as.factor(OCCUPATION) + UNION,
          data = merged_wages)
```
- Comparing estimation error of naive and robust estimation 

```{r, echo= TRUE}
sqrt(sum((coef(lm0) - coef(lm_merged))^2))
sqrt(sum((coef(lm0) - coef(rlm_merged))^2))
```

## Mixture model

- Now we try the mixure modeling approach with composite likelihood:

```{r, echo= TRUE}
source("../code/mixture_model.R")

X <- model.matrix(lm_merged)
X <- X[,!(colnames(X) %in% "(Intercept)")]
y <- model.extract(lm_merged$model, "response")
Xc <- apply(X, 2, function(z) z - mean(z))
yc <- y - mean(y)
tausq <- mean(yc^2)
f0 <- function(z) dnorm(z, mean = 0, sd = sqrt(tausq))

res <- fit_mixture(Xc, yc, f0, control = list(init = "robust"))
interc <- mean(y - X %*% res$betahat)
```


## Comparing the results

- Compute  $\| \widehat{\beta} - \widehat{\beta}_{LS}\|$, where $\widehat{\beta}_{LS}$ denotes the estimates from the original LS regression model with original data and $\widehat{\beta}$ is the estimate from, \text{N\"ive}, Huber, or mixture models.

```{r, echo= TRUE}
coef_mixture <- c(interc, res$betahat)
```

## Comparing the results (continued)

```{r, echo= TRUE}

sqrt(sum((coef(lm0) - coef_mixture)^2))
sqrt(sum((coef(lm0) - coef(rlm_merged))^2))
sqrt(sum((coef(lm0) - coef(lm_merged))^2))
```


## Blocking method using information information about the linkage process



## Histohram of duplicates

```{r, echo = FALSE, class = "blue-outline", fig.dim= c(4,3)}
source("../code/lahiri_larsen.R")
blockix <- merged_wages$A.ZIPCODE 
barplot(table(as.numeric(table(blockix))))
```

## Compute the estimates

```{r, echo= TRUE}
beta_Q <- coef(lahiri_larsen_block(Xc, yc, blockix))
Q <- generate_Q_block(blockix) 
beta_Q_check <- lahiri_larsen(Xc, yc, Q)
    
interc <- mean(y - X %*% beta_Q)
coef_Q <- c(interc, beta_Q)
```

- Compute $\| \widehat{\beta} - \widehat{\beta}_{LS}\|$:

```{r, echo=TRUE}
sqrt(sum((coef(lm0) - coef_Q)^2))
```

## Re-matching based on sorting

```{r, echo=TRUE}
source("../code/optimal_matching.R")

pihat <- optimal_matching(drop(Xc %*% res$betahat)
        , yc, blockix)
pihatinv <- order(pihat)
pistar <- match(merged_wages[,"B.ID"],
        merged_wages[,"A.ID"])
```

## Plot of mismatches

```{r, class = "blue-outline", fig.dim= c(3.6,3.6)}
plot(wages_f$WAGE[merged_wages[,"A.ID"]], 
     wages_f$WAGE[merged_wages[,"B.ID"]],
     xlab = " wages in the linked data", ylab = "wages in the original data")
points(wages_f$WAGE[merged_wages[,"A.ID"]],
       wages_f$WAGE[merged_wages[pihat,"B.ID"]], col = "red")
```
